\chapter{Sistema de resolución de conflictos}
En este capítulo se propondrá el marco teórico y el esquema aplicativo del sistema de resolución de conflictos a utilizar en el marco de MAPC.

\section{Información necesaria}
Después de estudiar el flujo de información y el contenido de la base de conocimiento de cada uno de nuestros agentes, sabemos que en cada turno un agente conoce su conjunto completo de creencias, deseos, y tiene al menos una intención persistente y bien determinada, al igual que \textit{al menos} una acción a realizar a futuro. Recordemos, además, que gracias al Servidor de Percepciones cada agente tiene una visión unificada del mundo y conoce los roles, posiciones y características físicas de sus compañeros de equipo.

Consideremos el agregado a la arquitectura mostrado; luego de esta nueva fase de comunicación, todos los agentes conocen la decisión tomada por sus compañeros de equipo, incluyendo tanto la intención más fuerte como la acción a realizar por cada uno de ellos.  Toda esta información, en conjunto, puede ser utilizada con el fin de re-analizar concretamente cuán potencialmente beneficiosa, peligrosa o perjudicial es la acción a realizar por el agente, y reconsiderar al respecto.

\section{Propuesta de coordinación}

Mostraremos ahora la primer posibilidad de coordinación propuesta; este sistema fue propuesto para ser utilizado durante la competencia MAPC 2011, y si bien no pudo ser presentado por falta de tiempo, existen algunas versiones en estado \textit{beta} ya implementadas.

\subsection{Prioridad de las intenciones}
Dado que el sistema provee suficiente flexibilidad como para permitir definir
distintas estrategias de resolución de acuerdo a la táctica utilizada en la fase
actual del juego, el primer paso es escribir un conjunto de órdenes de prioridad para las intenciones acorde a dichas fases.
Por ejemplo, si los agentes consideraran tres fases diferentes del juego (exploración, conquista de zonas y defensa del terreno), se debe contar con tres órdenes de prioridad, uno para cada respectiva fase. Esto resulta en que el sistema de resolución propuesto permita modificar el comportamiento de los agentes de manera dinámica según el estado
de la simulación, en lugar de resolver los potenciales conflictos siempre del mismo modo. Los órdenes de prioridad escritos indicarán la importancia de las posibles intenciones de los agentes en una fase determinada del juego.
A modo de ejemplo, durante los primeros veinte turnos de la simulación, el orden de prioridad puede ser definido de manera tal que se priorice la exploración del mapa a la expansión de zonas; de esta manera, los agentes pueden obtener mayor información del escenario para elaborar mejores planes a la hora de conquistar zonas del mapa.

Una vez que contamos con los órdenes de prioridad, el agente utilizará todo el
conocimiento de las características físicas y las intenciones y acciones
inminentes de sus compañeros para re-evaluar la propia. Es importante mencionar
que, en este esquema de coordinación, cuando un agente decide que realizar la
acción que había elegido deja de ser conveniente, pasa a actuar de manera
\textit{segura}, en el sentido de que realiza acciones que garantizan (o al
menos, maximizan las chances de) que no haya conflictos con otros agentes o
riesgo de pérdida de puntos. Se detallarán las potenciales acciones a realizar en \textit{modo seguro} en la sección siguiente, y más adelante analizaremos alternativas de acción que puedan dar aún más rédito.

\subsection{Clasificación de conflictos}
Existen diferentes tipos de conflicto que los agentes pueden encontrar al
momento de reconsiderar su decisión respecto a la manera de actuar.

Resulta natural pensar, por ejemplo, que si dos o más agentes van a realizar una acción persiguiendo
una intención idéntica (y que dicha acción/intención deba ser
realizada una única vez), entonces es un malgasto de recursos (energía) que
todos ellos la realicen. Un ejemplo de este caso ocurre cuando dos agentes
cualesquiera tienen como intención survey($X_{i}$) o cuando dos exploradores
tienen como intención probear($X_{i}$) para el mismo \textit{i}, o cuando dos inspectores tienen como
intención inspect estando en el mismo nodo. En cualquiera de estos
casos, resulta evidente que sólo uno de los agentes debería llevar a cabo la
acción. El criterio específico para decidir cuál de ellos la realiza puede ser
definido de muchas maneras; el propuesto para la competencia fue dejar que el
agente que pudiera efectivizar la intención en menor cantidad de turnos
realizara la acción, y en caso de empate, dejar que el que tuviera más energía
fuera el ganador. Si ambas condiciones resultaran en empate, el ganador se
determina por orden lexicográfico, pasando todos los perdedores a actuar en \textit{modo seguro}.

Sin embargo, no todos los casos en los que dos o más agentes tengan exactamente
la misma intención resultan conflictivos: por ejemplo, dos saboteadores pueden
querer atacar de manera simultánea a un mismo enemigo. Esta situación da lugar a
la clasificación de todas las intenciones en dos tipos: \textit{cooperativas} y
\textit{excluyentes}.

Por último, existen conflictos más complejos para su detección y
resolución; por ejemplo, supongamos una zona dominada por el equipo, con dos agentes delimitando una de las fronteras en dos nodos consecutivos; si ambos agentes decidieran intentar expandir la zona para aumentar el puntaje ganado en cada turno al mismo tiempo, y se movieran en direcciones opuestas separándose de manera que queden \textit{dos} nodos vacíos en medio de ellos, el control de la zona se perdería, resultando en una gran pérdida de puntos.
%que dos agentes decidan moverse para expandir una zona ya dominada, y que el movimiento sincronizado resulte en la pérdida de la zona.

A continuación, propondremos cómo detectar y resolver todos estos conflictos.

\subsection{Detección de conflictos}

Una vez finalizada la segunda fase de comunicación, cada agente considera las
intenciones y acciones a realizar de los demás miembros del equipo en busca de
potenciales conflictos.

El primer paso consiste en ordenar a los agentes de acuerdo al orden de prioridad establecido a las intenciones para la fase del juego actual. La intención que cada agente persigue será utilizada para definir, en caso de conflicto, cuáles de los agentes podrán continuar y cuáles deberán realizar otro tipo de acción que no resulte perjudicial.%bla bla bla bla bla

El paso siguiente es verificar si otros agentes tienen una
intención \textit{excluyente} que coincida con la propia. Si ese es el caso, se
evalúa cuál de dichos agentes se encuentra en mejor estado para efectivizar
la intención (de acuerdo a, como se mencionó antes, la cantidad de turnos
que necesitará para efectivizarla, seguido en caso de empate por la energía de cada uno de ellos, y por último según el orden lexicográfico de sus nombres).
Por razones de optimización, en las versiones beta ya implementadas del sistema los agentes proveen en la última fase de comunicación la cantidad de turnos que suponen necesitar para efectivizar la intención (considerando siempre el mejor caso; es decir, que no ocurran condiciones de corte, ataques enemigos, o cambios de plan repentinos).% mencionar que en versiones futuras se puede incluir TODO EL PLAN de los agentes (es decir, todos los pasos que van a seguir), para posiblemente argumentar sobre la mejor decisión con eso (?)

A continuación, en caso de que la etapa anterior no haya detectado ningún conflicto, se pasa a la fase más compleja de la detección; dado que cada agente que provoque cambios en su posición en el mapa puede afectar el control de las zonas dominadas, el sistema realiza una simulación progresiva de los puntos que el equipo puede obtener de acuerdo a las nuevas hipotéticas posiciones de cada agente. Esta simulación es llamada \textit{progresiva} porque se realiza corriendo una instancia del algoritmo de coloreo por cada nueva posición hipotética de los agentes. Recordando que los miembros del equipo se encuentran ordenados de acuerdo a la prioridad de sus intenciones, el sistema comienza calculando el puntaje según las posiciones originales de todos los agentes \textit{excepto el que tiene la mayor prioridad para moverse}; a partir de este puntaje base, se vuelve a correr el algoritmo de coloreo con la nueva posición hipotética del segundo agente mejor priorizado; este puntaje se compara con el puntaje base del primer cálculo,% mayor o igual? definir threshold?
y si es mayor o igual, pasa a ser el nuevo puntaje de referencia.

Los cálculos continúan repitiéndose posicionando a cada agente en su nueva posición hipotética. Si efectivamente la acción mejora o mantiene igual el puntaje obtenido en el turno, entonces se considera que esta acción no resulta perjudicial para el equipo. En caso contrario, se interpreta que la acción a tomar por el agente conflictivo es peligrosa, y ese agente debe pasar a actuar en \textit{modo seguro}; por lo tanto, la siguiente instancia del algoritmo para calcular el puntaje del equipo se corre con el agente conflictivo en su posición original, y continuando con la nueva posición hipotética del siguiente agente, hasta haber evaluado las acciones de todos ellos.

\subsection{Resolución de conflictos}

A continuación detallaremos el método utilizado para resolver los conflictos detectados por el sistema, así como algunas alternativas de acción en trabajos a futuro.

\subsubsection{Acciones seguras}

En caso de que en la fase de resolución de conflictos un agente detecte que su acción a realizar es perjudicial, el diseño actual distribuido hace que el agente tenga la responsabilidad de actuar en \textit{modo seguro}. Este modo de actuar implica realizar acciones que puedan beneficiar de alguna manera al equipo, pero sin correr riesgo de pérdida de puntaje global; es decir, el agente realiza cualquier acción \textit{que no implique movimiento} y suponga algún tipo de mejora a no realizar ninguna acción. Un ejemplo válido de acción segura para todos los roles de agente es la acción \textit{recharge}; por lo tanto, si el movimiento de un agente puede causar pérdida mayor de puntos, éste puede limitarse a recuperar su energía y buscar otra acción útil el turno siguiente. La acción \textit{survey} también resulta extremadamente útil en esta situación, dado que proveerá información del mapa a todos los demás agentes en el turno siguiente gracias al Servidor de Percepciones. Por último, el impedimento para desplazarse convierte al turno en una excelente oportunidad para que los agentes realicen la acción \textit{buy} para mejorar sus características físicas, en caso de que el equipo tenga créditos suficientes.

Considerando, además, los roles de los agentes, podemos definir otras acciones \textit{seguras}: los exploradores pueden realizar la acción \textit{probe} sobre el nodo en el que se encuentran parados sin ningún tipo de riesgo, aportando además información valiosa sobre el mapa a sus compañeros. Los saboteadores tienen la posibilidad de atacar enemigos cercanos sin moverse, convirtiéndola también en una acción \textit{segura}. Los inspectores pueden realizar la acción \textit{inspect} sobre cualquier enemigo cercano, los reparadores pueden ayudar a sus compañeros a recuperar su salud sin desplazarse, y por último, los reparadores, saboteadores y sentinelas pueden realizar \textit{parry} para intentar prevenir ataques enemigos.

Si bien probablemente ninguna de las acciones alternativas resulte óptima en vista del estado del escenario, se ha comprobado empíricamente luego de diez mil simulaciones de trescientos cincuenta turnos cada una, que el cambio a \textit{modo seguro} de los agentes resulta extremadamente beneficioso para el puntaje del equipo.% esto quizás se pueda poner en las conclusiones!

\subsubsection{Trabajo a futuro}

Como se mencionó anteriormente, el actual sistema de resolución de conflictos mejora el comportamiento de los agentes y el puntaje obtenido por el equipo. Sin embargo, dado que las acciones tomadas por los agentes conflictivos generalmente no resultan óptimas, es evidente que hay mucho trabajo por realizar a futuro en la etapa de reconsideración de acciones.

La primer mejora posible respecto al sistema actual consiste en hacer que los agentes comuniquen no sólo la cantidad de pasos de simulación que esperan necesitar para efectivizar su intención actual, sino también todo el plan que formularon para ello; de esta manera, los agentes pueden realizar predicciones más efectivas respecto al movimiento de sus compañeros y la cantidad de puntos que puede obtener el equipo en corto y mediano plazo, considerando la eventual posibilidad de sacrificar puntos en turnos cercanos para conseguir un mayor puntaje global a mediano plazo.

Otra mejora que surge naturalmente en el sistema es no limitar a los agentes a realizar únicamente acciones \textit{seguras}; como punto de partida, es posible hacer que los agentes agreguen a su base de conocimiento el argumento \textit{NO X}, siendo \textit{X} la acción conflictiva detectada por el sistema, y realizar el proceso argumentativo una vez más, y repetir la detección de conflicto. En corto tiempo se llegaría a un estado en el que todos los agentes realizan la que consideran la mejor acción sin perjudicar al resto de sus compañeros mejor priorizados, y a partir de una decisión tomada con mayor criterio que el de selección de una acción \textit{segura}. Al comienzo del turno siguiente, el argumento agregado podría ser eliminado, dejando la chance de que el agente reconsidere realizar la acción nuevamente con la eventual posibilidad de no perjudicar a sus compañeros.

Por último, un cambio más radical pero muy interesante a nivel académico consiste en modificar la cantidad de información compartida por los agentes a partir del Servidor de Percepciones, haciendo que los agentes no conozcan la información sobre las características físicas de sus compañeros. Luego de la fase de toma de decisión por parte de los agentes, una vez que se detectan conflictos por intenciones \textit{excluyentes}, los agentes involucrados podrían utilizar Argumentación Rebatible para decidir cuál es más apto para realizar la tarea; y mejor aún, sería posible implementar negociación entre los agentes para intentar obtener ayuda de los propios compañeros. Por otro lado, también podría utilizarse Argumentación Rebatible para resolver los conflictos más complejos utilizando como argumentos las predicciones de cada uno de los agentes del estado del escenario a futuro a partir de sus acciones.