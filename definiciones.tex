\chapter{Definiciones preeliminares} % Contexto de la tesis (background formal, y contexto del desarrollo
En este capítulo se revisarán algunas definiciones de conceptos técnicos, para posteriormente utilizarlos sin ambiguedad durante el resto de la presentación.

\section*{Agente inteligente}
Un agente es una entidad computacional autónoma, que puede percibir su entorno a través de sensores, y actuar en dicho entorno utilizando efectores. Usualmente, la información que un agente percibe de su entorno es sólo parcial. Los agentes toman decisiones a partir de la información contenida en su base de conocimiento, siguiendo diferentes conjuntos de reglas propuestas, y actúan de manera acorde a la decisión tomada. Dichas acciones, a su vez, pueden producir efectos en el entorno.\\
Actualmente los agentes tienen un campo de aplicación muy amplio y existen
muchos tipos de agentes diferentes (por ejemplo: \textit{reactivos}, \textit{deliberativos},
\textit{inteligentes}, \textit{de interface}, \textit{colaborativos}), los cuales a su vez están
orientados a distintos entornos de aplicación.\\
En la mayoría de los casos, los agentes no existen por sí solos, sino que participan de un Sistema Multi-Agente (SMA).

%El objetivo particular de este proyecto es la aplicación de Argumentación para
%la implementación de diálogos entre agentes inmersos en un escenario con
%objetivos determinados. Puntualmente, se enfocará la investigación a la
%plataforma propuesta en el Multi-Agent Programming Contest, un juego académico
%donde agentes independientes compiten por diferentes objetivos.\\
%Sin embargo, el desarrollo de herramientas para implementar tales formalismos se encuentra en
%progreso y a un paso más lento. Además, muchas de las herramientas disponibles
%carecen de una base formal y suelen ser simplemente un entorno de desarrollo
%amigable.\\
 En un SMA, varios agentes
interactúan para conseguir algún objetivo o realizar alguna tarea . En este
tipo de sistemas, cada agente tiene información incompleta y capacidades
limitadas, el control del sistema es distribuido, los datos están
descentralizados, y la computación es asincrónica. Además, los agentes se
desenvuelven en un entorno dinámico y cambiante, el cual no puede predecirse y
se ve afectado por las acciones que son llevadas a cabo por los agentes y
también por humanos.\\
%Un aspecto importante en SMA es la comunicación entre agentes, la cual puede
ser necesaria para que los agentes compitan o cooperen de acuerdo a sus metas
individuales.


\section*{Sistema Multi-Agente}
Es un sistema en el cual muchos agentes interactúan para conseguir algún objetivo o realizar alguna tarea común. En los
sistemas multiagente, cada agente tiene información incompleta y capacidades limitadas, el control del sistema es distribuido, los datos están descentralizados, y la computación es asincrónica. Los agentes se desenvuelven en un entorno dinámico y cambiante, el cual no puede predecirse y se ve afectado por las acciones que son llevadas a cabo. Los diálogos con otros agentes del mismo ambiente son, actualmente, un área de estudio intensivo.

\section*{Inteligencia Artificial Distribuida}
Es el estudio, construcción y aplicación de Sistemas Multi-Agente.

\section*{Arquitectura BDI}
El modelo BDI (\textit{Belief-Desire-Intentions}) es tanto una teoría como una arquitectura de agentes. Un agente BDI posee un conjunto de \textbf{creencias}, un conjunto de \textbf{deseos}, y otro de \textbf{intenciones}. Las intenciones representan un conjunto de alternativas que el agente posee para alcanzar sus metas, y tienen la propiedad de ser \textbf{persistentes}; el agente mantiene todas sus intenciones hasta que logre cumplirlas, o bien se de cuenta de que \textit{no} podrá cumplirlas, o bien, por algún otro motivo, las razones que tuvo para adoptar por primera vez a la intención dejaron de ser válidas.\\
A grandes rasgos, la arquitectura BDI propone que el agente:
\begin{enumerate}
	\item Perciba los cambios del entorno en el que se desenvuelve.
	\item Revise sus creencias del mundo en base a la percepción.
	\item Razone acerca de sus intenciones para reconsiderarlas, de ser necesario.
	\item Seleccione una acción a seguir, razonando sobre sus creencias e intenciones.
	\item Ejecute la acción seleccionada, y vuelva al primer paso.
\end{enumerate}

\section*{Argumentación rebatible}
La argumentación rebatible es un mecanismo de razonamiento no monótono en donde
la aceptación o el rechazo de una proposición dependen de un análisis entre
argumentos a favor y en contra de esa proposición. Usualmente es utilizada bajo
diferentes formalizaciones para capturar aspectos del razonamiento del sentido
común y la representación de información incompleta y potencialmente
inconsistente.\\
En particular, la toma de decisiones de los agentes inteligentes realizada por nuestro equipo en el marco de la competencia MAPC 2011, fue realizada utilizando Argumentación rebatible via DeLP. (cita!)

\section*{DeLP}
DeLP (Defeasible-Logic Programming) es...
%aca mentir MUCHO.

\section{Multi-Agent Programming Contest}
El \textit{Multi-Agent Programming Contest} es un concurso de programación de
Inteligencia Artificial iniciado en el año 2005 con el objetivo de estimular la
investigación en el área de desarrollo y programación de Sistemas Multi-Agente.
Para ello, la competencia propone diferentes escenarios de juego de manera
anual, que obligan a los participantes tanto a identificar y resolver problemas
clave, como a explorar lenguajes, plataformas y herramientas de programación
para Sistemas Multi-Agente.

\subsection{Escenario MAPC 2011}

El escenario del año 2011 está formado por el mapa de un planeta representado
mediante un grafo. Cada nodo del grafo es una locación válida (y tiene un valor
determinado), y existen arcos (con diferente costo de energía) que permiten a un
agente desplazarse de una locación a otra.\\
En cada ronda de la competición participan dos equipos rivales. Cada equipo
posee un conjunto de agentes con diferentes roles preestablecidos
(\textit{Explorador}, \textit{Saboteador}, \textit{Reparador},
\textit{Sentinela} e \textit{Inspector}). El rol de cada agente define tanto el
conjunto de acciones que puede realizar, como sus características físicas
(\textit{Energía}, \textit{Salud}, \textit{Fuerza} y \textit{Rango de
Visión}).\\
\subsubsection{Puntaje}
La simulación del juego se desarrolla por pasos, y en cada paso se otorga a los
equipos una determinada cantidad de puntos según el estado de la simulación. El
objetivo del juego es obtener la mayor cantidad de puntos posibles cuando la
simulación termina.\\
Para obtener puntos, los agentes de cada uno de los equipos deben lograr formar
\textit{"`zonas"'} en el mapa logrando posicionarse en diferentes locaciones de
manera estratégica. La predominancia de un equipo sobre el otro en los nodos es
determinada por un algoritmo bien definido para la competencia, y el valor de
todos los nodos dominados por un equipo es el principal factor del puntaje
otorgado en cada uno de los pasos de la simulación. Algunas otras situaciones,
como el logro de determinados \textit{achievements}, pueden otorgar puntos
adicionales y dinero al equipo.
\subsubsection{Acciones}
Todos los agentes tienen acciones en común que pueden realizar en cada uno de
los pasos de la simulación:
\begin{itemize}
	\item goto(X): el agente se desplaza hacia el nodo X, siempre y cuando
exista un arco que conecte el nodo actual del agente con X, y dicho arco tenga
un costo menor a la energía actual del agente.
	\item survey(X): el agente recibe en su próxima percepción los costos de
todos los arcos conectados al nodo en el que se encuentra actualmente.
	\item buy(X): el agente utiliza el dinero obtenido a partir de los
\textit{achievements} para aumentar el valor máximo de cualquiera de sus
características físicas (Energía, Salud, Fuerza o Rango de visión) en 1 punto.
	\item recharge: el agente recupera el 20\% de su energía máxima.
	\item skip: el agente pasa al turno siguiente sin realizar ningún tipo
de acción.
\end{itemize}

Además, según el rol de cada agente, existen algunas acciones específicas que
pueden realizar:
\begin{itemize}
	\item attack(X): acción disponible únicamente para los \textit{Saboteadores}; el
agente ataca a un enemigo X, si dicho enemigo se encuentra en el mismo nodo. El
ataque, de tener éxito, decrementa la energía del agente enemigo, pudiendo
deshabilitarlo en caso de que ésta llegue a 0.
	\item parry: acción disponible únicamente para los \textit{Reparadores},
\textit{Saboteadores} y \textit{Sentinelas}. La acción protege al agente de los ataques enemigos,
impidiendo que éstos tengan éxito.
	\item probe: acción disponible únicamente para los \textit{Exploradores}. El
agente recibe en su próxima percepción el valor del nodo en el que se encuentra
actualmente. Ésta acción no sólo resulta importante por conocer el valor del
nodo, sino que además permite que, cuando el nodo es conquistado por el equipo,
dicho valor se sume al total de puntos de la zona. Un nodo en el que no se
realizó \textit{probe} suma únicamente 1 punto al valor total de la zona.
	\item inspect: acción disponible únicamente para los \texit{Inspectores}. El
inspector recibe en su próxima percepción la información física (Salud, Energía,
Fuerza, Rango de visión) de todos los agentes enemigos que se encuentren en el
mismo nodo que él, o en cualquier vecino directo.
	\item repair(X): acción disponible únicamente para los \textit{Reparadores}. El
reparador aumenta el valor de la Salud actual de su compañero de equipo X
(volviendo a habilitarlo, en caso de que su Salud fuera 0).

\end{itemize}

\subsubsection{Toma de decisiones y motivación para la resolución de conflictos}
A diferencia de los años anteriores, esta competencia apunta a lograr un buen
Sistema Multi-Agente puramente distribuido; esto significa que cada agente debe
realizar el proceso de toma de decisiones por su cuenta, en lugar de
contar con una inteligencia centralizada que decida cuál será la acción a
realizar para cada uno de los agentes.\\
Dado que cada agente decide por separado qué acción tomar, muchas veces ocurre que dos (o más) de los agentes del mismo
equipo realizan acciones que resultan redundantes, peligrosas, y en el peor de
los casos, perjudiciales al combinarse. Si bien por limitaciones temporales únicamente se realizaron coordinaciones implícitas en las acciones de los agentes, es naturalmente posible mejorar dicha coordinación para sacar mayor rédito de las acciones.